# Intercom RAG Pipeline

Pipeline automatizado para processar artigos do Intercom Help Center usando **Contextual Retrieval** da Anthropic, com anÃ¡lise de imagens por VLM e chunking semÃ¢ntico inteligente.

## ğŸš€ Funcionalidades

- **Busca incremental** de artigos via API do Intercom
- **Processamento de imagens** com GPT-4 Vision para converter imagens em descriÃ§Ãµes textuais
- **LLM Chunking** semÃ¢ntico que usa GPT para dividir o texto de forma inteligente
- **Contextual Retrieval** baseado na metodologia da Anthropic para melhorar precisÃ£o de busca em ~35%
- **Embeddings vetoriais** com OpenAI `text-embedding-3-small`
- **Storage MongoDB** com upsert idempotente
- **Suporte multilÃ­ngue** com filtros personalizÃ¡veis por artigo
- **CategorizaÃ§Ã£o automÃ¡tica** de artigos por tipo de conteÃºdo

## ğŸ—ï¸ Arquitetura do Pipeline

```
Intercom API â†’ Image Processing (GPT-4V) â†’ HTMLâ†’Markdown â†’ CategorizaÃ§Ã£o â†’ 
LLM Chunking â†’ Contextual Enrichment â†’ Limpeza Condicional â†’ Embeddings â†’ MongoDB Storage
```

### Etapas do Processamento

1. **Parsing & Image Analysis**
   - Converte HTML para Markdown preservando estrutura semÃ¢ntica
   - Usa GPT-4 Vision para descrever imagens em contexto
   - Remove imagens decorativas de cabeÃ§alhos automaticamente

2. **CategorizaÃ§Ã£o Inteligente**
   - Classifica artigos em: `technical_support`, `features`, `billing_plans_and_pricing`, `troubleshooting`, `how_to`
   - Usa LLM para anÃ¡lise de tÃ­tulo + conteÃºdo

3. **LLM Chunking SemÃ¢ntico**
   - GPT decide onde dividir o texto baseado no conteÃºdo
   - Separa por plataformas (Kyte PDV, Kyte Web)
   - MantÃ©m coerÃªncia semÃ¢ntica em cada chunk

4. **Contextual Enrichment**
   - Adiciona contexto a cada chunk usando metodologia da Anthropic
   - Formato: `"Contexto: [explicaÃ§Ã£o]\n---\n[chunk original]"`
   - Melhora significativamente a precisÃ£o do retrieval

5. **Limpeza Condicional**
   - Aplica limpeza inteligente apenas quando necessÃ¡rio
   - Preserva formataÃ§Ã£o semÃ¢ntica atÃ© o final do pipeline
   - Remove apenas ruÃ­dos visuais para otimizar embeddings

## ğŸ“ Estrutura do Projeto

```
intercom-rag-pipeline/
â”œâ”€â”€ .env                           # VariÃ¡veis de ambiente
â”œâ”€â”€ .gitignore                     # Arquivos ignorados pelo Git
â”œâ”€â”€ requirements.txt               # DependÃªncias Python
â”œâ”€â”€ README.md                      # Esta documentaÃ§Ã£o
â”œâ”€â”€ run_intercom_pipeline.py       # Script principal
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py               # ConfiguraÃ§Ãµes centralizadas
â””â”€â”€ src/
    â”œâ”€â”€ api/
    â”‚   â””â”€â”€ intercom_client.py    # Cliente API Intercom
    â”œâ”€â”€ processing/
    â”‚   â”œâ”€â”€ image_processor.py     # AnÃ¡lise de imagens (GPT-4V)
    â”‚   â”œâ”€â”€ text_processor.py      # HTMLâ†’Markdown preservando estrutura
    â”‚   â”œâ”€â”€ chunker.py            # LLM Chunking semÃ¢ntico
    â”‚   â”œâ”€â”€ contextual_enricher.py # Contextual Retrieval
    â”‚   â””â”€â”€ categorizer.py        # CategorizaÃ§Ã£o automÃ¡tica
    â”œâ”€â”€ mongodb/
    â”‚   â””â”€â”€ mongodb_client.py     # Cliente MongoDB
    â””â”€â”€ utils/
        â”œâ”€â”€ embeddings.py         # GeraÃ§Ã£o de embeddings
        â””â”€â”€ text_cleaner.py       # Limpeza condicional unificada
```

## âš¡ InstalaÃ§Ã£o

### PrÃ©-requisitos
- Python 3.8+
- MongoDB Atlas ou instÃ¢ncia local
- Conta OpenAI com acesso Ã  API
- Token de acesso do Intercom

### Setup RÃ¡pido

1. **Clone o repositÃ³rio**
```bash
git clone <seu-repo>
cd intercom-rag-pipeline
```

2. **Instale as dependÃªncias**
```bash
pip install -r requirements.txt
```

3. **Configure as variÃ¡veis de ambiente**
```bash
cp .env.example .env
```

Edite o arquivo `.env` com suas credenciais:
```env
# OpenAI
OPENAI_API_KEY=sk-your-key-here

# Intercom
INTERCOM_API_TOKEN=your-intercom-token
INTERCOM_BASE_URL=https://api.intercom.io

# MongoDB
MONGODB_CONNECTION_STRING=mongodb+srv://user:pass@cluster.mongodb.net/
KYTE_DBNAME_AI=kyte-ai
KYTE_COLLECTION_NAME=KyteFAQKnowledgeBase

# Modelos AI
EMBEDDING_MODEL=text-embedding-3-small
RAG_SYNTH_MODEL=gpt-4o-mini
RAG_IMAGE_PROCESSOR_MODEL=gpt-4o
RAG_CONTEXTUAL_ENRICHER_MODEL=gpt-4o-mini
RAG_CHUNKER_MODEL=gpt-4o-mini
RAG_CATEGORIZER_MODEL=gpt-4o-mini

# ConfiguraÃ§Ãµes
MAX_CHUNK_SIZE=2000
EMBEDDING_DIMENSIONS=1536
```

4. **Execute o pipeline**
```bash
python run_intercom_pipeline.py
```

## âš™ï¸ ConfiguraÃ§Ã£o AvanÃ§ada

### Filtros de Idioma por Artigo

O pipeline suporta configuraÃ§Ã£o granular de idiomas:

```python
# IDs que devem processar todos os idiomas (PT, EN, ES)
MULTILINGUAL_ARTICLE_IDS = [
    "7861149", "7915496", "8411647", "8887223", "7915619",
    "7861109", "10008263", "7885145", "7992438", "7914908"
]

# Demais artigos processam apenas PT-BR
# Artigos excluÃ­dos do processamento
EXCLUDED_ARTICLE_IDS = ["7861154"]
```

### Filtro por ColeÃ§Ã£o RAG

```python
# Para processar apenas artigos de uma coleÃ§Ã£o especÃ­fica
RAG_COLLECTION_ID = "123456"  # None para processar todos
```

## ğŸ¯ Uso

### ExecuÃ§Ã£o BÃ¡sica
```bash
python run_intercom_pipeline.py
```

### Logs Detalhados
O pipeline fornece logs completos do processamento:

```
ğŸš€ Iniciando pipeline de processamento de artigos da Intercom...
ğŸ“‹ Pipeline: HTML â†’ Markdown â†’ Categorizar â†’ Chunking â†’ Enriquecimento â†’ Limpeza â†’ Embeddings
ğŸŒ EstratÃ©gia de idiomas: PT-BR por padrÃ£o, mÃºltiplos idiomas para artigos especÃ­ficos

ğŸ“Š Total de artigos encontrados: 45
ğŸ“„ Processando Artigo ID: 7861149, Idioma: pt-BR, Estado: published
 -> Categoria identificada: how_to
 -> Iniciando chunking semÃ¢ntico...
 -> Gerados 3 chunks semÃ¢nticos
 -> Iniciando enriquecimento contextual...
 -> Enriquecidos 3 chunks com contexto
âœ… Artigo 7861149 processado: 3 documentos gerados

ğŸ“ˆ Resumo do processamento:
 â€¢ Artigos processados: 42
   - MultilÃ­ngues (PT/EN/ES): 10
   - Apenas PT-BR: 32
 â€¢ Artigos pulados: 3
 â€¢ Total de documentos gerados: 156

ğŸ’¾ Salvando 156 documentos no MongoDB...
âœ… Documentos salvos com sucesso!
```

## ğŸ“Š Estrutura dos Dados

### Documento no MongoDB
```json
{
  "title": "Como cadastrar produtos fracionados no Kyte",
  "content": "[Contexto: Este chunk explica o cadastro de produtos fracionados no Kyte PDV] Para cadastrar um produto fracionado...",
  "category": "how_to",
  "language": "pt-BR",
  "embedding": [0.123, -0.456, ...],
  "meta_data": {
    "source_type": "intercom_help_center_article",
    "article_id": "12260744",
    "intercom_url": "https://docs.kyteapp.com/...",
    "intercomCreatedAt": "2024-01-15T10:30:00Z",
    "intercomUpdatedAt": "2024-01-20T14:45:00Z",
    "article_state": "published",
    "rag_collection_id": null,
    "is_chunked": true,
    "chunk_index": 0,
    "total_chunks": 4,
    "embedding_model": "text-embedding-3-small",
    "dimensions": 1536,
    "is_multilingual_article": false
  }
}
```

### Chave de IdempotÃªncia
```javascript
{
  "meta_data.article_id": "12260744",
  "meta_data.language": "pt-BR", 
  "meta_data.chunk_index": 0
}
```

## ğŸ“š ReferÃªncias

- [Contextual Retrieval - Anthropic](https://www.anthropic.com/news/contextual-retrieval)
- [Intercom API Documentation](https://developers.intercom.com/docs/)
- [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)
- [MongoDB Python Driver](https://pymongo.readthedocs.io/)
- [Best Practices for RAG](https://docs.llamaindex.ai/en/stable/optimizing/production_rag/)

---

## ğŸ¯ Quick Start Checklist

- [ ] Clone o repositÃ³rio
- [ ] Instalar dependÃªncias (`pip install -r requirements.txt`)
- [ ] Configurar `.env` com todas as chaves
- [ ] Testar conexÃµes (OpenAI, Intercom, MongoDB)
- [ ] Executar pipeline (`python run_intercom_pipeline.py`)
- [ ] Verificar dados no MongoDB
- [ ] Configurar filtros de idioma se necessÃ¡rio
